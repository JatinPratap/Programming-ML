{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gzip\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jatin\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is to showcase the usecase of files option - we set the \"read\" option and checking in terms of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data_file= r'C:\\Users\\jatin\\Desktop\\reviews_data.txt.gz'\n",
    "\n",
    "with gzip.open (data_file,'rb') as f:\n",
    "    for i,line in enumerate(f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yield is use to get generator ( same like return value, but more optmized in the memory allocation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utils.simple_preprocess - it will covert into lowercase and it will also convert into tokens, we dont have to use the NLTK library. The limit is 3 words to 15 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected output lowercase tokens\n",
    "def read_input(input_file):\n",
    "    with gzip.open (data_file,'rb') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            #do some preprocessing and return list of words for each review\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oct', 'nice', 'trendy', 'hotel', 'location', 'not', 'too', 'bad', 'stayed', 'in', 'this', 'hotel', 'for', 'one', 'night', 'as', 'this', 'is', 'fairly', 'new', 'place', 'some', 'of', 'the', 'taxi', 'drivers', 'did', 'not', 'know', 'where', 'it', 'was', 'and', 'or', 'did', 'not', 'want', 'to', 'drive', 'there', 'once', 'have', 'eventually', 'arrived', 'at', 'the', 'hotel', 'was', 'very', 'pleasantly', 'surprised', 'with', 'the', 'decor', 'of', 'the', 'lobby', 'ground', 'floor', 'area', 'it', 'was', 'very', 'stylish', 'and', 'modern', 'found', 'the', 'reception', 'staff', 'geeting', 'me', 'with', 'aloha', 'bit', 'out', 'of', 'place', 'but', 'guess', 'they', 'are', 'briefed', 'to', 'say', 'that', 'to', 'keep', 'up', 'the', 'coroporate', 'image', 'as', 'have', 'starwood', 'preferred', 'guest', 'member', 'was', 'given', 'small', 'gift', 'upon', 'check', 'in', 'it', 'was', 'only', 'couple', 'of', 'fridge', 'magnets', 'in', 'gift', 'box', 'but', 'nevertheless', 'nice', 'gesture', 'my', 'room', 'was', 'nice', 'and', 'roomy', 'there', 'are', 'tea', 'and', 'coffee', 'facilities', 'in', 'each', 'room', 'and', 'you', 'get', 'two', 'complimentary', 'bottles', 'of', 'water', 'plus', 'some', 'toiletries', 'by', 'bliss', 'the', 'location', 'is', 'not', 'great', 'it', 'is', 'at', 'the', 'last', 'metro', 'stop', 'and', 'you', 'then', 'need', 'to', 'take', 'taxi', 'but', 'if', 'you', 'are', 'not', 'planning', 'on', 'going', 'to', 'see', 'the', 'historic', 'sites', 'in', 'beijing', 'then', 'you', 'will', 'be', 'ok', 'chose', 'to', 'have', 'some', 'breakfast', 'in', 'the', 'hotel', 'which', 'was', 'really', 'tasty', 'and', 'there', 'was', 'good', 'selection', 'of', 'dishes', 'there', 'are', 'couple', 'of', 'computers', 'to', 'use', 'in', 'the', 'communal', 'area', 'as', 'well', 'as', 'pool', 'table', 'there', 'is', 'also', 'small', 'swimming', 'pool', 'and', 'gym', 'area', 'would', 'definitely', 'stay', 'in', 'this', 'hotel', 'again', 'but', 'only', 'if', 'did', 'not', 'plan', 'to', 'travel', 'to', 'central', 'beijing', 'as', 'it', 'can', 'take', 'long', 'time', 'the', 'location', 'is', 'ok', 'if', 'you', 'plan', 'to', 'do', 'lot', 'of', 'shopping', 'as', 'there', 'is', 'big', 'shopping', 'centre', 'just', 'few', 'minutes', 'away', 'from', 'the', 'hotel', 'and', 'there', 'are', 'plenty', 'of', 'eating', 'options', 'around', 'including', 'restaurants', 'that', 'serve', 'dog', 'meat']\n"
     ]
    }
   ],
   "source": [
    "documents=list(read_input(data_file))\n",
    "print(documents[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec works on Nerual network. It works based on the context -- predicts the next words ( CBOW apporach )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window size ( 7 words ) : { Nice trendy hotel \"location\" is not too bad  } - Based on the surrounding words it will select. And the loop will keep on going "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Train word2vec model\n",
    "model=gensim.models.Word2Vec(documents,vector_size=50,window=10,min_count=2,workers=10)\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector_size=50 - bascially we are creating words -> Numbers matrix/vector - we are setting up the size as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=model.wv['happy']\n",
    "vector.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_similar with this function WRT the word vector, we can check for the related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7345448136329651),\n",
       " ('horrible', 0.7096846103668213),\n",
       " ('horrendous', 0.6818950176239014),\n",
       " ('poor', 0.6708788871765137),\n",
       " ('disappointing', 0.656162440776825),\n",
       " ('tolerable', 0.6503310799598694),\n",
       " ('greatest', 0.6481829881668091),\n",
       " ('alright', 0.6465232372283936),\n",
       " ('dissapointing', 0.6460315585136414),\n",
       " ('pathetic', 0.6458064317703247)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1='bad'\n",
    "model.wv.most_similar(positive=w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648183"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('bad','greatest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('capacities', 0.5190680027008057),\n",
       " ('durves', 0.50001060962677),\n",
       " ('enthusiam', 0.49637264013290405),\n",
       " ('campers', 0.47981229424476624),\n",
       " ('graco', 0.4741586148738861),\n",
       " ('morans', 0.4698413908481598),\n",
       " ('wendella', 0.4691399931907654),\n",
       " ('macaroons', 0.46428918838500977),\n",
       " ('agnes', 0.4609362781047821),\n",
       " ('naz', 0.4505580961704254)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1='bad'\n",
    "model.wv.most_similar(negative=w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Train word2vec model\n",
    "model2=gensim.models.Word2Vec(documents,vector_size=50,window=10,min_count=2,workers=10,sg=1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
