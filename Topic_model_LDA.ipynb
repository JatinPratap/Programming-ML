{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gzip\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups # 20 news categories\n",
    "newsgroup_train=fetch_20newsgroups(subset='train',shuffle=True)\n",
    "newsgroup_test=fetch_20newsgroups(subset='test',shuffle=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# print list\n",
    "print(list(newsgroup_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(newsgroup_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroup_train.data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(newsgroup_train.filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(newsgroup_train.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform preprocessing steps \n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v'))  #every pasttese into present tesne\n",
    "\n",
    "# Tokenize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3: \n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list\n",
    "preprocessed_docs=[]\n",
    "\n",
    "for doc in newsgroup_train.data:\n",
    "    preprocessed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary \n",
    "dictionary=gensim.corpora.Dictionary(preprocessed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61411"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 addit\n",
      "1 bodi\n",
      "2 bricklin\n",
      "3 bring\n",
      "4 bumper\n",
      "5 call\n",
      "6 colleg\n",
      "7 door\n",
      "8 earli\n",
      "9 engin\n",
      "10 enlighten\n",
      "11 funki\n",
      "12 histori\n",
      "13 host\n",
      "14 info\n",
      "15 know\n",
      "16 late\n",
      "17 lerxst\n",
      "18 line\n",
      "19 look\n",
      "20 mail\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count+=1\n",
    "    if count>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15,no_above=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BOW model for each doc we create one dic how many words and how many times those words appear \n",
    "bow_corpus=[dictionary.doc2bow(doc) for doc in preprocessed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 83 (\"email\") appears 1 time.\n",
      "Word 145 (\"newsread\") appears 1 time.\n",
      "Word 156 (\"version\") appears 1 time.\n",
      "Word 522 (\"collin\") appears 2 time.\n",
      "Word 523 (\"east\") appears 1 time.\n",
      "Word 524 (\"fort\") appears 2 time.\n",
      "Word 525 (\"harmoni\") appears 1 time.\n",
      "Word 526 (\"hewlett\") appears 2 time.\n",
      "Word 527 (\"packard\") appears 2 time.\n",
      "Word 528 (\"regard\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preview BOW for our sample preprocessed document\n",
    "'''\n",
    "document_num = 12\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using Bag of words\n",
    "lda_model=gensim.models.LdaMulticore(bow_corpus,num_topics=8,id2word=dictionary,\n",
    "                                    passes=10,workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic :0 \n",
      "words :0.013*\"imag\" + 0.011*\"file\" + 0.007*\"program\" + 0.007*\"avail\" + 0.007*\"graphic\" + 0.007*\"window\" + 0.007*\"version\" + 0.007*\"server\" + 0.006*\"softwar\" + 0.006*\"widget\"\n",
      "\n",
      "\n",
      "Topic :1 \n",
      "words :0.007*\"bike\" + 0.005*\"drive\" + 0.005*\"engin\" + 0.004*\"car\" + 0.004*\"power\" + 0.004*\"light\" + 0.003*\"leav\" + 0.003*\"speed\" + 0.003*\"turn\" + 0.003*\"littl\"\n",
      "\n",
      "\n",
      "Topic :2 \n",
      "words :0.017*\"game\" + 0.015*\"team\" + 0.011*\"play\" + 0.010*\"player\" + 0.007*\"hockey\" + 0.006*\"season\" + 0.005*\"leagu\" + 0.005*\"score\" + 0.004*\"basebal\" + 0.003*\"divis\"\n",
      "\n",
      "\n",
      "Topic :3 \n",
      "words :0.011*\"encrypt\" + 0.010*\"govern\" + 0.009*\"chip\" + 0.008*\"secur\" + 0.008*\"clipper\" + 0.007*\"public\" + 0.006*\"key\" + 0.005*\"wire\" + 0.005*\"protect\" + 0.004*\"escrow\"\n",
      "\n",
      "\n",
      "Topic :4 \n",
      "words :0.013*\"space\" + 0.011*\"nasa\" + 0.006*\"program\" + 0.005*\"presid\" + 0.005*\"research\" + 0.004*\"list\" + 0.004*\"servic\" + 0.004*\"launch\" + 0.004*\"orbit\" + 0.004*\"nation\"\n",
      "\n",
      "\n",
      "Topic :5 \n",
      "words :0.010*\"christian\" + 0.006*\"exist\" + 0.006*\"jesus\" + 0.005*\"moral\" + 0.004*\"bibl\" + 0.004*\"life\" + 0.004*\"religion\" + 0.004*\"atheist\" + 0.004*\"evid\" + 0.004*\"human\"\n",
      "\n",
      "\n",
      "Topic :6 \n",
      "words :0.015*\"window\" + 0.012*\"drive\" + 0.010*\"card\" + 0.009*\"file\" + 0.007*\"program\" + 0.006*\"disk\" + 0.006*\"scsi\" + 0.006*\"control\" + 0.006*\"driver\" + 0.005*\"softwar\"\n",
      "\n",
      "\n",
      "Topic :7 \n",
      "words :0.007*\"armenian\" + 0.006*\"israel\" + 0.006*\"kill\" + 0.005*\"isra\" + 0.005*\"jew\" + 0.004*\"govern\" + 0.004*\"turkish\" + 0.004*\"live\" + 0.003*\"arab\" + 0.003*\"countri\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the topics\n",
    "for id,topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic :{} \\nwords :{}\".format(id,topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: carter@ecf.toronto.edu (CARTER EDWARD A)\n",
      "Subject: Re: Good Reasons to Wave at each other\n",
      "Organization: University of Toronto, Engineering Computing Facility\n",
      "Lines: 19\n",
      "\n",
      "jlevine@rd.hydro.on.ca (Jody Levine) writes:\n",
      ">Has anyone, while driving a cage, ever waved at bikers? I get the urge,\n",
      ">but I've never actually done it.\n",
      "\n",
      "Oh yeah, all the time.  On a nice spring/summer day, I roll down the window\n",
      "and drive around looking for bikes.  When a bike motors by in the opposite\n",
      "direction, I stick my arm out and hi5'em.  My arm feels like a million \n",
      "bucks when I'm doing this a 60km/h.  I do the same thing with cyclists.\n",
      "The only problem with hi5ing a cyclist is their always in the right hand lane.\n",
      "I hafta roll down the other window and hi5 them on the back.  Oh well, I \n",
      "think they appreciate the thought. \n",
      "\n",
      "Regards, Ted.\n",
      "\n",
      "---\n",
      "University of Toronto Computer Engineering               \n",
      "PowerUsersGroupChairman\n",
      "'89 FZR600: I'm taking a ride with my best friend.                  DoD#:886699\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test model unseen document\n",
    "unseen_doc=newsgroup_test.data[50]\n",
    "print(unseen_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "bow_vector=dictionary.doc2bow(preprocess(unseen_doc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are printing the topic  Index ( above 7 topics we have given ), also we are putting index 5 so that it will send all the words it has for that topic. 5 words are more than enough ani i kept that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.8042205572128296? \n",
      "Topic :0.007*\"bike\" + 0.005*\"drive\" + 0.005*\"engin\" + 0.004*\"car\" + 0.004*\"power\" \n",
      "Score:0.13118712604045868? \n",
      "Topic :0.017*\"game\" + 0.015*\"team\" + 0.011*\"play\" + 0.010*\"player\" + 0.007*\"hockey\" \n",
      "Score:0.051262930035591125? \n",
      "Topic :0.015*\"window\" + 0.012*\"drive\" + 0.010*\"card\" + 0.009*\"file\" + 0.007*\"program\" \n"
     ]
    }
   ],
   "source": [
    "for index,score in sorted(lda_model[bow_vector]):\n",
    "    print(\"Score:{}? \\nTopic :{} \".format(score,lda_model.print_topic(index,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Topic 8\n"
     ]
    }
   ],
   "source": [
    "print('Actual Topic',newsgroup_test.target[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(list(newsgroup_test.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
